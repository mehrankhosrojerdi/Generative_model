{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`What is the activation function?  `\n",
        "\n",
        "Activation functions apply a non-linear transformation and decide whether a neuron should be activated or not.  \n",
        "\n",
        "There are different types of activation funaction that we can use and here we mention some of them.\n",
        "\n",
        "1. Sigmoid: Its output values are between 0 and 1. It is used in the last layer of a binary classification model. The problem with the sigmoid activation function is gradient vanishing and it doesn't apply to hidden layers.  \n",
        "\n",
        "2. TanH: Hyperbolic Tanjant is an activation that has the gradient vanishing problem because its shape is like a sigmoid activation function. Its output value is between 1 and -1\n",
        "\n",
        "3. ReLU: Rectified Linear Unit is an activation that if the input is negative the output is zero and if it is positive it simply returns x. Its problem is about dying some nodes because the derivative of zero is zero and technically we remove some nodes from our neural network and in fact this occurance happened in the backpropagation process which by using the LeakyReLU and ELU we can solve its problem.    \n",
        "\n",
        "4. Leaky ReLU (used to prevent nodes' death inside the neural network)  \n",
        "\n",
        "5. Softmax (this is a probability classification). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
